


     
Question 1 - Implement 3 different CNN architectures with a comparison table for the MNSIT dataset using the Tensorflow library. Note -

The model parameters for each architecture should not be more than 8000
parameters 2. Code comments should be given for proper code understanding. 3. The minimum accuracy for each accuracy should be at least 96%


import tensorflow as tf
from tensorflow.keras import layers

# Load and preprocess the MNIST dataset
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train = x_train.reshape(-1, 28, 28, 1) / 255.0
x_test = x_test.reshape(-1, 28, 28, 1) / 255.0

# Define the first CNN architecture
model_1 = tf.keras.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Compile and train the first model
model_1.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])
model_1.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))

# Define the second CNN architecture
model_2 = tf.keras.Sequential([
    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Compile and train the second model
model_2.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])
model_2.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))

# Define the third CNN architecture
model_3 = tf.keras.Sequential([
    layers.Conv2D(8, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.Conv2D(16, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Compile and train the third model
model_3.compile(optimizer='adam',
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy'])
model_3.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))

     
Epoch 1/10
  31/1875 [..............................] - ETA: 33s - loss: 1.4758 - accuracy: 0.5565
---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
<ipython-input-2-970a1a2681a2> in <cell line: 23>()
     21                 loss='sparse_categorical_crossentropy',
     22                 metrics=['accuracy'])
---> 23 model_1.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))
     24 
     25 # Define the second CNN architecture

/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)
     63         filtered_tb = None
     64         try:
---> 65             return fn(*args, **kwargs)
     66         except Exception as e:
     67             filtered_tb = _process_traceback_frames(e.__traceback__)

/usr/local/lib/python3.10/dist-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1683                         ):
   1684                             callbacks.on_train_batch_begin(step)
-> 1685                             tmp_logs = self.train_function(iterator)
   1686                             if data_handler.should_sync:
   1687                                 context.async_wait()

/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py in error_handler(*args, **kwargs)
    148     filtered_tb = None
    149     try:
--> 150       return fn(*args, **kwargs)
    151     except Exception as e:
    152       filtered_tb = _process_traceback_frames(e.__traceback__)

/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py in __call__(self, *args, **kwds)
    892 
    893       with OptionalXlaContext(self._jit_compile):
--> 894         result = self._call(*args, **kwds)
    895 
    896       new_tracing_count = self.experimental_get_tracing_count()

/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py in _call(self, *args, **kwds)
    924       # In this case we have created variables on the first call, so we run the
    925       # defunned version which is guaranteed to never create variables.
--> 926       return self._no_variable_creation_fn(*args, **kwds)  # pylint: disable=not-callable
    927     elif self._variable_creation_fn is not None:
    928       # Release the lock early so that multiple threads can perform the call

/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py in __call__(self, *args, **kwargs)
    141       (concrete_function,
    142        filtered_flat_args) = self._maybe_define_function(args, kwargs)
--> 143     return concrete_function._call_flat(
    144         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access
    145 

/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1755         and executing_eagerly):
   1756       # No tape is watching; skip to running the function.
-> 1757       return self._build_call_outputs(self._inference_function.call(
   1758           ctx, args, cancellation_manager=cancellation_manager))
   1759     forward_backward = self._select_forward_and_backward_functions(

/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py in call(self, ctx, args, cancellation_manager)
    379       with _InterpolateFunctionError(self):
    380         if cancellation_manager is None:
--> 381           outputs = execute.execute(
    382               str(self.signature.name),
    383               num_outputs=self._num_outputs,

/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     50   try:
     51     ctx.ensure_initialized()
---> 52     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     53                                         inputs, attrs, num_outputs)
     54   except core._NotOkStatusException as e:

KeyboardInterrupt: 
Question 2 - Implement 5 different CNN architectures with a comparison table for CIFAR 10 dataset using the PyTorch library Note -

The model parameters for each architecture should not be more than 10000
parameters 2 Code comments should be given for proper code understanding


import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms

# Load and preprocess the CIFAR-10 dataset
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)
testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)

# Define the first CNN architecture
class Model1(nn.Module):
    def __init__(self):
        super(Model1, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, 3)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(16 * 7 * 7, 64)
        self.fc2 = nn.Linear(64, 10)

    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = x.view(-1, 16 * 7 * 7)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

model1 = Model1()

# Define the second CNN architecture
class Model2(nn.Module):
    def __init__(self):
        super(Model2, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 3)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(32 * 7 * 7, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = x.view(-1, 32 * 7 * 7)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

model2 = Model2()

# Define the third CNN architecture
class Model3(nn.Module):
    def __init__(self):
        super(Model3, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, 3)
        self.conv2 = nn.Conv2d(16, 32, 3)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(32 * 6 * 6, 64)
        self.fc2 = nn.Linear(64, 10)

    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = x.view(-1, 32 * 6 * 6)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

model3 = Model3()

# Define the fourth CNN architecture
class Model4(nn.Module):
    def __init__(self):
        super(Model4, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 3)
        self.conv2 = nn.Conv2d(32, 64, 3)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(64 * 6 * 6, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = x.view(-1, 64 * 6 * 6)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

model4 = Model4()

# Define the fifth CNN architecture
class Model5(nn.Module):
    def __init__(self):
        super(Model5, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, 3)
        self.conv2 = nn.Conv2d(16, 32, 3)
        self.conv3 = nn.Conv2d(32, 64, 3)
        self.pool = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(64 * 5 * 5, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = self.pool(torch.relu(self.conv3(x)))
        x = x.view(-1, 64 * 5 * 5)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

model5 = Model5()

# Define the training parameters
criterion = nn.CrossEntropyLoss()
optimizer1 = optim.SGD(model1.parameters(), lr=0.01, momentum=0.9)
optimizer2 = optim.SGD(model2.parameters(), lr=0.01, momentum=0.9)
optimizer3 = optim.SGD(model3.parameters(), lr=0.01, momentum=0.9)
optimizer4 = optim.SGD(model4.parameters(), lr=0.01, momentum=0.9)
optimizer5 = optim.SGD(model5.parameters(), lr=0.01, momentum=0.9)

# Train the models and evaluate their accuracy
def train_model(model, optimizer):
    for epoch in range(10):
        running_loss = 0.0
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
        
        # Print the loss for each epoch
        print(f"Model Loss after epoch {epoch+1}: {running_loss / len(trainloader)}")

def test_model(model):
    correct = 0
    total = 0
    with torch.no_grad():
        for data in testloader:
            images, labels = data
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    accuracy = 100 * correct / total
    return accuracy

# Train and test each model
train_model(model1, optimizer1)
accuracy1 = test_model(model1)

train_model(model2, optimizer2)
accuracy2 = test_model(model2)

train_model(model3, optimizer3)
accuracy3 = test_model(model3)

train_model(model4, optimizer4)
accuracy4 = test_model(model4)

train_model(model5, optimizer5)
accuracy5 = test_model(model5)

# Create a comparison table
table = {
    'Model': ['Model 1', 'Model 2', 'Model 3', 'Model 4', 'Model 5'],
    'Accuracy (%)': [accuracy1, accuracy2, accuracy3, accuracy4, accuracy5],
    'Parameters': [sum(p.numel() for p in model1.parameters()), 
                   sum(p.numel() for p in model2.parameters()), 
                   sum(p.numel() for p in model3.parameters()), 
                   sum(p.numel() for p in model4.parameters()), 
                   sum(p.numel() for p in model5.parameters())]
}

# Display the comparison table
print("Comparison Table:")
print("-" * 40)
print("{:<8} {:<15} {:<12}".format('Model', 'Accuracy (%)', 'Parameters'))
print("-" * 40)
for row in table:
    print("{:<8} {:<15} {:<12}".format(row['Model'], row['Accuracy (%)'], row['Parameters']))

     
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz
100%|██████████| 170498071/170498071 [00:16<00:00, 10543092.56it/s]
Extracting ./data/cifar-10-python.tar.gz to ./data
Files already downloaded and verified
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-3-f6e99f6ccac3> in <cell line: 154>()
    152 
    153 # Train and test each model
--> 154 train_model(model1, optimizer1)
    155 accuracy1 = test_model(model1)
    156 

<ipython-input-3-f6e99f6ccac3> in train_model(model, optimizer)
    128             inputs, labels = data
    129             optimizer.zero_grad()
--> 130             outputs = model(inputs)
    131             loss = criterion(outputs, labels)
    132             loss.backward()

/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _call_impl(self, *args, **kwargs)
   1499                 or _global_backward_pre_hooks or _global_backward_hooks
   1500                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1501             return forward_call(*args, **kwargs)
   1502         # Do not call functions when jit is used
   1503         full_backward_hooks, non_full_backward_hooks = [], []

<ipython-input-3-f6e99f6ccac3> in forward(self, x)
     26     def forward(self, x):
     27         x = self.pool(torch.relu(self.conv1(x)))
---> 28         x = x.view(-1, 16 * 7 * 7)
     29         x = torch.relu(self.fc1(x))
     30         x = self.fc2(x)

RuntimeError: shape '[-1, 784]' is invalid for input of size 460800
Question 3 - Train a Pure CNN with less than 10000 trainable parameters using the MNIST Dataset having minimum validation accuracy of 99.40% Note -

Code comments should be given for proper code understanding.
Implement in both PyTorch and Tensorflow respectively
PyTorch


import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Define the CNN model
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, 3, 1)
        self.conv2 = nn.Conv2d(16, 32, 3, 1)
        self.fc1 = nn.Linear(32 * 5 * 5, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.relu(self.conv2(x))
        x = x.view(-1, 32 * 5 * 5)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Load the MNIST dataset
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)

# Initialize the model
model = CNN().to(device)

# Set the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# Training loop
epochs = 10
for epoch in range(epochs):
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
    
    # Evaluate the model on the test set
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            _, predicted = torch.max(output.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
    
    accuracy = 100 * correct / total
    print(f'Epoch [{epoch+1}/{epochs}], Test Accuracy: {accuracy:.2f}%')

    # Check if the minimum validation accuracy is reached
    if accuracy >= 99.4:
        break

     
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz
100%|██████████| 9912422/9912422 [00:00<00:00, 98766388.51it/s]
Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz
100%|██████████| 28881/28881 [00:00<00:00, 26123720.90it/s]
Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz
100%|██████████| 1648877/1648877 [00:00<00:00, 26546591.21it/s]
Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw

Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz
100%|██████████| 4542/4542 [00:00<00:00, 7121693.00it/s]
Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw

---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-4-422f6f47b0e5> in <cell line: 47>()
     50         data, target = data.to(device), target.to(device)
     51         optimizer.zero_grad()
---> 52         output = model(data)
     53         loss = criterion(output, target)
     54         loss.backward()

/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py in _call_impl(self, *args, **kwargs)
   1499                 or _global_backward_pre_hooks or _global_backward_hooks
   1500                 or _global_forward_hooks or _global_forward_pre_hooks):
-> 1501             return forward_call(*args, **kwargs)
   1502         # Do not call functions when jit is used
   1503         full_backward_hooks, non_full_backward_hooks = [], []

<ipython-input-4-422f6f47b0e5> in forward(self, x)
     19         x = torch.relu(self.conv1(x))
     20         x = torch.relu(self.conv2(x))
---> 21         x = x.view(-1, 32 * 5 * 5)
     22         x = torch.relu(self.fc1(x))
     23         x = self.fc2(x)

RuntimeError: shape '[-1, 800]' is invalid for input of size 1179648

import tensorflow as tf
from tensorflow.keras import layers, models, datasets

# Load the MNIST dataset
(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()

# Normalize pixel values to the range [0, 1]
train_images = train_images / 255.0
test_images = test_images / 255.0

# Define the CNN model
model = models.Sequential([
    layers.Reshape((28, 28, 1), input_shape=(28, 28)),
    layers.Conv2D(16, 3, activation='relu'),
    layers.Conv2D(32, 3, activation='relu'),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(10)
])

# Set the loss function and optimizer
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
optimizer = tf.keras.optimizers.Adam()

# Compile the model
model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])

# Training loop
epochs = 10
for epoch in range(epochs):
    model.fit(train_images, train_labels, batch_size=64, epochs=1, verbose=2)
    
    # Evaluate the model on the test set
    test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)
    print(f'Epoch [{epoch+1}/{epochs}], Test Accuracy: {test_accuracy*100:.2f}%')

    # Check if the minimum validation accuracy is reached
    if test_accuracy >= 0.994:
        break

     
Question 4 - Design an end-to-end solution with diagrams for object detection use cases leveraging AWS cloud services and open-source tech Note -

You need to use both AWS cloud services and open-source tech to design the
entire solution 2. The pipeline should consist of a data pipeline, ml pipeline, deployment pipeline, and inference pipeline. 3. In the data pipeline, you would be designing how to get the data from external or existing sources and tech used for the same 4. In the ml pipeline, you would be designing how to train the model, and what all algorithms, techniques, etc. would you be using. Again, tech used for the same 5. Since this is a deep learning project, the use of GPUs, and how effectively are you using them to optimize for cost and training time should also be taken into consideration. 6. In the deployment pipeline, you would be designing how effectively and efficiently you are deploying the model in the cloud, 7. In the inference pipeline, consider the cost of inference and its optimization related to computing resources and handling external traffic 8. You can use any tool to design the architecture 9. Do mention the pros and cons of your architecture and how much further it can be optimized and its tradeoffs. 10. Do include a retraining approach as well. 11. Try to include managed AWS resources for deep learning like AWS Textract, AWS Sagemaker, etc., and not just general-purpose compute resources like S3, EC2, etc. Try to mix the best of both services



     
